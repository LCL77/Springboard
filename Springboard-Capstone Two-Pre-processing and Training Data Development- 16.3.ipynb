{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD IN TOTAL HAPPINESS DATA and edu data  ONCE EVERYTHING IS FIXED IN WRAINGLING PART "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources \n",
    "\n",
    "1.https://ddf46429.springboard.com/uploads/resources/1584729764_Capstone_Two_Step_4__Preprocessing_Training_Data_Developmen_fIzkPuL.pdf\n",
    "2.https://aiden-dataminer.medium.com/the-data-science-method-dsm-pre-processing-and-training-data-development-fd2d75182967\n",
    "3.https://medium.com/@urvashilluniya/convert-multiple-categorical-columns-into-numeric-columns-in-single-line-of-code-577bab825635\n",
    "4.https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "5.https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directions\n",
    "\n",
    "The goal of the preprocessing work is to prepare your data\n",
    "for fitting models. If you identified some categorical features in your dataset in the EDA\n",
    "step, now is the time to create dummy features to allow for the inclusion of those\n",
    "features in your model development. Additionally, standardizing your features numeric\n",
    "magnitude and creating train and test splits happen in this step. You may want to save a\n",
    "version of your clean, preprocessed data frame as a CSV to access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np \n",
    "import json\n",
    "import statistics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "\n",
    "data_2020= pd.read_csv('2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country name</th>\n",
       "      <th>Regional indicator</th>\n",
       "      <th>Ladder score</th>\n",
       "      <th>Standard error of ladder score</th>\n",
       "      <th>upperwhisker</th>\n",
       "      <th>lowerwhisker</th>\n",
       "      <th>Logged GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Ladder score in Dystopia</th>\n",
       "      <th>Explained by: Log GDP per capita</th>\n",
       "      <th>Explained by: Social support</th>\n",
       "      <th>Explained by: Healthy life expectancy</th>\n",
       "      <th>Explained by: Freedom to make life choices</th>\n",
       "      <th>Explained by: Generosity</th>\n",
       "      <th>Explained by: Perceptions of corruption</th>\n",
       "      <th>Dystopia + residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.8087</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>7.869766</td>\n",
       "      <td>7.747634</td>\n",
       "      <td>10.639267</td>\n",
       "      <td>0.954330</td>\n",
       "      <td>71.900825</td>\n",
       "      <td>0.949172</td>\n",
       "      <td>-0.059482</td>\n",
       "      <td>0.195445</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.285190</td>\n",
       "      <td>1.499526</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>0.662317</td>\n",
       "      <td>0.159670</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>2.762835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.6456</td>\n",
       "      <td>0.033492</td>\n",
       "      <td>7.711245</td>\n",
       "      <td>7.579955</td>\n",
       "      <td>10.774001</td>\n",
       "      <td>0.955991</td>\n",
       "      <td>72.402504</td>\n",
       "      <td>0.951444</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>0.168489</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.326949</td>\n",
       "      <td>1.503449</td>\n",
       "      <td>0.979333</td>\n",
       "      <td>0.665040</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.495260</td>\n",
       "      <td>2.432741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.5599</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>7.628528</td>\n",
       "      <td>7.491272</td>\n",
       "      <td>10.979933</td>\n",
       "      <td>0.942847</td>\n",
       "      <td>74.102448</td>\n",
       "      <td>0.921337</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>0.303728</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.390774</td>\n",
       "      <td>1.472403</td>\n",
       "      <td>1.040533</td>\n",
       "      <td>0.628954</td>\n",
       "      <td>0.269056</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>2.350267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.5045</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>7.621347</td>\n",
       "      <td>7.387653</td>\n",
       "      <td>10.772559</td>\n",
       "      <td>0.974670</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.246944</td>\n",
       "      <td>0.711710</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.326502</td>\n",
       "      <td>1.547567</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>0.661981</td>\n",
       "      <td>0.362330</td>\n",
       "      <td>0.144541</td>\n",
       "      <td>2.460688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>7.4880</td>\n",
       "      <td>0.034837</td>\n",
       "      <td>7.556281</td>\n",
       "      <td>7.419719</td>\n",
       "      <td>11.087804</td>\n",
       "      <td>0.952487</td>\n",
       "      <td>73.200783</td>\n",
       "      <td>0.955750</td>\n",
       "      <td>0.134533</td>\n",
       "      <td>0.263218</td>\n",
       "      <td>1.972317</td>\n",
       "      <td>1.424207</td>\n",
       "      <td>1.495173</td>\n",
       "      <td>1.008072</td>\n",
       "      <td>0.670201</td>\n",
       "      <td>0.287985</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>2.168266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country name Regional indicator  Ladder score  \\\n",
       "0      Finland     Western Europe        7.8087   \n",
       "1      Denmark     Western Europe        7.6456   \n",
       "2  Switzerland     Western Europe        7.5599   \n",
       "3      Iceland     Western Europe        7.5045   \n",
       "4       Norway     Western Europe        7.4880   \n",
       "\n",
       "   Standard error of ladder score  upperwhisker  lowerwhisker  \\\n",
       "0                        0.031156      7.869766      7.747634   \n",
       "1                        0.033492      7.711245      7.579955   \n",
       "2                        0.035014      7.628528      7.491272   \n",
       "3                        0.059616      7.621347      7.387653   \n",
       "4                        0.034837      7.556281      7.419719   \n",
       "\n",
       "   Logged GDP per capita  Social support  Healthy life expectancy  \\\n",
       "0              10.639267        0.954330                71.900825   \n",
       "1              10.774001        0.955991                72.402504   \n",
       "2              10.979933        0.942847                74.102448   \n",
       "3              10.772559        0.974670                73.000000   \n",
       "4              11.087804        0.952487                73.200783   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  \\\n",
       "0                      0.949172   -0.059482                   0.195445   \n",
       "1                      0.951444    0.066202                   0.168489   \n",
       "2                      0.921337    0.105911                   0.303728   \n",
       "3                      0.948892    0.246944                   0.711710   \n",
       "4                      0.955750    0.134533                   0.263218   \n",
       "\n",
       "   Ladder score in Dystopia  Explained by: Log GDP per capita  \\\n",
       "0                  1.972317                          1.285190   \n",
       "1                  1.972317                          1.326949   \n",
       "2                  1.972317                          1.390774   \n",
       "3                  1.972317                          1.326502   \n",
       "4                  1.972317                          1.424207   \n",
       "\n",
       "   Explained by: Social support  Explained by: Healthy life expectancy  \\\n",
       "0                      1.499526                               0.961271   \n",
       "1                      1.503449                               0.979333   \n",
       "2                      1.472403                               1.040533   \n",
       "3                      1.547567                               1.000843   \n",
       "4                      1.495173                               1.008072   \n",
       "\n",
       "   Explained by: Freedom to make life choices  Explained by: Generosity  \\\n",
       "0                                    0.662317                  0.159670   \n",
       "1                                    0.665040                  0.242793   \n",
       "2                                    0.628954                  0.269056   \n",
       "3                                    0.661981                  0.362330   \n",
       "4                                    0.670201                  0.287985   \n",
       "\n",
       "   Explained by: Perceptions of corruption  Dystopia + residual  \n",
       "0                                 0.477857             2.762835  \n",
       "1                                 0.495260             2.432741  \n",
       "2                                 0.407946             2.350267  \n",
       "3                                 0.144541             2.460688  \n",
       "4                                 0.434101             2.168266  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Country name                                153 non-null    object \n",
      " 1   Regional indicator                          153 non-null    object \n",
      " 2   Ladder score                                153 non-null    float64\n",
      " 3   Standard error of ladder score              153 non-null    float64\n",
      " 4   upperwhisker                                153 non-null    float64\n",
      " 5   lowerwhisker                                153 non-null    float64\n",
      " 6   Logged GDP per capita                       153 non-null    float64\n",
      " 7   Social support                              153 non-null    float64\n",
      " 8   Healthy life expectancy                     153 non-null    float64\n",
      " 9   Freedom to make life choices                153 non-null    float64\n",
      " 10  Generosity                                  153 non-null    float64\n",
      " 11  Perceptions of corruption                   153 non-null    float64\n",
      " 12  Ladder score in Dystopia                    153 non-null    float64\n",
      " 13  Explained by: Log GDP per capita            153 non-null    float64\n",
      " 14  Explained by: Social support                153 non-null    float64\n",
      " 15  Explained by: Healthy life expectancy       153 non-null    float64\n",
      " 16  Explained by: Freedom to make life choices  153 non-null    float64\n",
      " 17  Explained by: Generosity                    153 non-null    float64\n",
      " 18  Explained by: Perceptions of corruption     153 non-null    float64\n",
      " 19  Dystopia + residual                         153 non-null    float64\n",
      "dtypes: float64(18), object(2)\n",
      "memory usage: 24.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2020.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Training Data Development\n",
    "\n",
    "Goal: Create a cleaned development dataset you can use to complete the\n",
    "modeling step of your project. Pre-processing is the concept of standardizing your model development dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dummy or indicator features for categorical variables\n",
    "- Hint: you’ll need to think about your old favorite pandas functions here like get_dummies() . Consult this guide for help.\n",
    "- First, we select all the columns that are categorical which are those with the data type = ‘object’, creating a data frame subset named ‘dfo’. Next, we concatenate the original data frame df while dropping those columns selected in the dfo, df.drop(dfo,axis=1), with the pandas.get_dummies(dfo) command, creating only indicator columns for the selected object data type columns and collating it with other numeric data frame columns.\n",
    "- you do not pass your dummy aka indicator features to the scaler; they do not need to be scaled as they as are boolean representations of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all the columns that are categorical, ‘object’, creating a data frame subset \n",
    "dummy = pd.get_dummies(data_2020['Country name'])\n",
    "dummy2 = pd.get_dummies(data_2020['Regional indicator'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Azerbaijan</th>\n",
       "      <th>Bahrain</th>\n",
       "      <th>Bangladesh</th>\n",
       "      <th>...</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>Venezuela</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zambia</th>\n",
       "      <th>Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Afghanistan  Albania  Algeria  Argentina  Armenia  Australia  Austria  \\\n",
       "0            0        0        0          0        0          0        0   \n",
       "1            0        0        0          0        0          0        0   \n",
       "2            0        0        0          0        0          0        0   \n",
       "3            0        0        0          0        0          0        0   \n",
       "4            0        0        0          0        0          0        0   \n",
       "\n",
       "   Azerbaijan  Bahrain  Bangladesh  ...  United Arab Emirates  United Kingdom  \\\n",
       "0           0        0           0  ...                     0               0   \n",
       "1           0        0           0  ...                     0               0   \n",
       "2           0        0           0  ...                     0               0   \n",
       "3           0        0           0  ...                     0               0   \n",
       "4           0        0           0  ...                     0               0   \n",
       "\n",
       "   United States  Uruguay  Uzbekistan  Venezuela  Vietnam  Yemen  Zambia  \\\n",
       "0              0        0           0          0        0      0       0   \n",
       "1              0        0           0          0        0      0       0   \n",
       "2              0        0           0          0        0      0       0   \n",
       "3              0        0           0          0        0      0       0   \n",
       "4              0        0           0          0        0      0       0   \n",
       "\n",
       "   Zimbabwe  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Central and Eastern Europe</th>\n",
       "      <th>Commonwealth of Independent States</th>\n",
       "      <th>East Asia</th>\n",
       "      <th>Latin America and Caribbean</th>\n",
       "      <th>Middle East and North Africa</th>\n",
       "      <th>North America and ANZ</th>\n",
       "      <th>South Asia</th>\n",
       "      <th>Southeast Asia</th>\n",
       "      <th>Sub-Saharan Africa</th>\n",
       "      <th>Western Europe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Central and Eastern Europe  Commonwealth of Independent States  East Asia  \\\n",
       "0                           0                                   0          0   \n",
       "1                           0                                   0          0   \n",
       "2                           0                                   0          0   \n",
       "3                           0                                   0          0   \n",
       "4                           0                                   0          0   \n",
       "\n",
       "   Latin America and Caribbean  Middle East and North Africa  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             0   \n",
       "3                            0                             0   \n",
       "4                            0                             0   \n",
       "\n",
       "   North America and ANZ  South Asia  Southeast Asia  Sub-Saharan Africa  \\\n",
       "0                      0           0               0                   0   \n",
       "1                      0           0               0                   0   \n",
       "2                      0           0               0                   0   \n",
       "3                      0           0               0                   0   \n",
       "4                      0           0               0                   0   \n",
       "\n",
       "   Western Europe  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country name Regional indicator  Ladder score  \\\n",
      "0      Finland     Western Europe        7.8087   \n",
      "1      Denmark     Western Europe        7.6456   \n",
      "2  Switzerland     Western Europe        7.5599   \n",
      "3      Iceland     Western Europe        7.5045   \n",
      "4       Norway     Western Europe        7.4880   \n",
      "\n",
      "   Standard error of ladder score  upperwhisker  lowerwhisker  \\\n",
      "0                        0.031156      7.869766      7.747634   \n",
      "1                        0.033492      7.711245      7.579955   \n",
      "2                        0.035014      7.628528      7.491272   \n",
      "3                        0.059616      7.621347      7.387653   \n",
      "4                        0.034837      7.556281      7.419719   \n",
      "\n",
      "   Logged GDP per capita  Social support  Healthy life expectancy  \\\n",
      "0              10.639267        0.954330                71.900825   \n",
      "1              10.774001        0.955991                72.402504   \n",
      "2              10.979933        0.942847                74.102448   \n",
      "3              10.772559        0.974670                73.000000   \n",
      "4              11.087804        0.952487                73.200783   \n",
      "\n",
      "   Freedom to make life choices  ...  United Arab Emirates  United Kingdom  \\\n",
      "0                      0.949172  ...                     0               0   \n",
      "1                      0.951444  ...                     0               0   \n",
      "2                      0.921337  ...                     0               0   \n",
      "3                      0.948892  ...                     0               0   \n",
      "4                      0.955750  ...                     0               0   \n",
      "\n",
      "   United States  Uruguay  Uzbekistan  Venezuela  Vietnam  Yemen  Zambia  \\\n",
      "0              0        0           0          0        0      0       0   \n",
      "1              0        0           0          0        0      0       0   \n",
      "2              0        0           0          0        0      0       0   \n",
      "3              0        0           0          0        0      0       0   \n",
      "4              0        0           0          0        0      0       0   \n",
      "\n",
      "   Zimbabwe  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "#concatenate the original data frame df while dropping those columns selected\n",
    "\n",
    "#Concat new columns to original dataframe \n",
    "df_concat = pd.concat([data_2020, dummy2, dummy], axis=1)\n",
    "print (df_concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ladder score  Standard error of ladder score  upperwhisker  lowerwhisker  \\\n",
      "0        7.8087                        0.031156      7.869766      7.747634   \n",
      "1        7.6456                        0.033492      7.711245      7.579955   \n",
      "2        7.5599                        0.035014      7.628528      7.491272   \n",
      "3        7.5045                        0.059616      7.621347      7.387653   \n",
      "4        7.4880                        0.034837      7.556281      7.419719   \n",
      "\n",
      "   Logged GDP per capita  Social support  Healthy life expectancy  \\\n",
      "0              10.639267        0.954330                71.900825   \n",
      "1              10.774001        0.955991                72.402504   \n",
      "2              10.979933        0.942847                74.102448   \n",
      "3              10.772559        0.974670                73.000000   \n",
      "4              11.087804        0.952487                73.200783   \n",
      "\n",
      "   Freedom to make life choices  Generosity  Perceptions of corruption  ...  \\\n",
      "0                      0.949172   -0.059482                   0.195445  ...   \n",
      "1                      0.951444    0.066202                   0.168489  ...   \n",
      "2                      0.921337    0.105911                   0.303728  ...   \n",
      "3                      0.948892    0.246944                   0.711710  ...   \n",
      "4                      0.955750    0.134533                   0.263218  ...   \n",
      "\n",
      "   United Arab Emirates  United Kingdom  United States  Uruguay  Uzbekistan  \\\n",
      "0                     0               0              0        0           0   \n",
      "1                     0               0              0        0           0   \n",
      "2                     0               0              0        0           0   \n",
      "3                     0               0              0        0           0   \n",
      "4                     0               0              0        0           0   \n",
      "\n",
      "   Venezuela  Vietnam  Yemen  Zambia  Zimbabwe  \n",
      "0          0        0      0       0         0  \n",
      "1          0        0      0       0         0  \n",
      "2          0        0      0       0         0  \n",
      "3          0        0      0       0         0  \n",
      "4          0        0      0       0         0  \n",
      "\n",
      "[5 rows x 181 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-bb1a16b837dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_concat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##Drop corresponding categorical columns and first dummy variable columns.\n",
    "\n",
    "df_concat.drop(['Country name','Regional indicator'], inplace=True, axis=1)\n",
    "print (df_concat.head())\n",
    "\n",
    "df.drop(dfo,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into testing and training datasets \n",
    "- Hint: don’t forget your sklearn functions here, like train_test_split(). \n",
    "- we apply it in two steps, first defining the scaler based on the mean and standard deviation of the training data and then applying that scaler to each the training and testing sets.\n",
    "- Implementing a data subset approach with a train and test split with a 70/30 or 80/20 split is the general rule for an effective holdout test data for model validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-c7e98ef00c02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_2020\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_2020\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5141\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#train_test_split()\n",
    "\n",
    "# spliting training and testing data\n",
    "#x= data, y=target dependent variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_2020.data\n",
    "y = data_2020.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the mean and STD of the training data\n",
    "\n",
    "#train_test_split()\n",
    "\n",
    "# spliting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\n",
    "\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "def dt_splitter(date_col, X, y, test_size):\n",
    "        xw_date=pd.DataFrame(X).merge(date_col,left_index=True, right_index=True)\n",
    "        ad = (max(xw_date.date)- min(xw_date.date)).days*test_size\n",
    "        split_date = min(xw_date.date) + timedelta(days=ad)\n",
    "        X_train = xw_date.loc[xw_date['date'] <= split_date].drop(['date'], axis=1).values\n",
    "        X_test = xw_date.loc[xw_date['date'] > split_date].drop(['date'], axis=1).values\n",
    "        yw_date=pd.DataFrame(y).merge(date_col,left_index=True, right_index=True)\n",
    "        y_train=yw_date.loc[yw_date['date'] <= split_date].drop(['date'], axis=1).values\n",
    "        y_test=yw_date.loc[yw_date['date'] > split_date].drop(['date'], axis=1).values\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the magnitude of numeric features using a scale\n",
    "\n",
    "- Hint: you might need to employ Python code like this: Making a Scaler object\n",
    "\n",
    "- scaler = preprocessing.StandardScaler()\n",
    "\n",
    "Fitting data to the scaler object\n",
    "\n",
    "- scaled_df = scaler.fit_transform(df)\n",
    "- scaled_df = pd.DataFrame(scaled_df, columns=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Finland'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-5d3784c2a6b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# fit and transform the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_2020\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Finland'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# the scaler object (model)\n",
    "scaler = StandardScaler()\n",
    "# fit and transform the data\n",
    "scaled_data = scaler.fit_transform(data_2020) \n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify that the mean of each feature (column) is 0:\n",
    "\n",
    "scaled_data.mean(axis = 0)\n",
    "array([0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify that the std of each feature (column) is 1:\n",
    "\n",
    "scaled_data.std(axis = 0)\n",
    "array([1., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ladder Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ladder Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-bcfe31ea481e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test = train_test_split(X, y,\n\u001b[1;32m----> 5\u001b[1;33m                                                     \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_2020\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ladder Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                                                     test_size=0.25)\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ladder Score'"
     ]
    }
   ],
   "source": [
    "#Does the data need to be stratified\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=data_2020['Ladder Score'], \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the following questions and apply them to your dataset:\n",
    "\n",
    "- Does my data set have any categorical data, such as Gender or day of the week?\n",
    "\n",
    "Yes, Regional indicator. \n",
    "\n",
    "- Do my features have data values that range from 0 - 100 or 0-1 or both and more? \n",
    "\n",
    "Yes, both. Features like GDP, Healthy life expectancy are 0-100, Ladder Score is 0-10, and Social Support, Genorosity and the majority of the other features are on a 0-1 scale. \n",
    "- https://en.wikipedia.org/wiki/World_Happiness_Report#Methodology\n",
    "- https://worldhappiness.report/faq/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input array\n",
    "X_predict = targets[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "\n",
    "# Predict with the model\n",
    "predictions = model.predict(X_predict)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# Visualize predictions and actual values\n",
    "plt.scatter(X_predict['petal length (cm)'], X_predict['petal width (cm)'],\n",
    "            c=predictions, cmap=plt.cm.coolwarm)\n",
    "plt.title(\"Predicted class values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy indicator \n",
    "\n",
    "get_dummies()\n",
    "\n",
    "dfo=df.select_dtypes(include=['object']) # select object type columns\n",
    "df = pd.concat([df.drop(dfo, axis=1), pd.get_dummies(dfo)], axis=1)\n",
    "\n",
    "# data standardization with  sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# copy of datasets\n",
    "X_train_stand = X_train.copy()\n",
    "X_test_stand = X_test.copy()\n",
    "\n",
    "# numerical features\n",
    "num_cols = ['Item_Weight','Item_Visibility','Item_MRP','Outlet_Establishment_Year']\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    X_test_stand[i] = scale.transform(X_test_stand[[i]])\n",
    "    \n",
    "\n",
    "scaler = StandardScaler()\n",
    "df2 = data_2020.DataFrame(scaler.fit_transform(df),\n",
    "                   columns=['WEIGHT','PRICE'],\n",
    "                   index = ['Orange','Apple','Banana','Grape'])\n",
    "ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow'], \n",
    "                     marker = '*',s=80, label='BREFORE SCALING');\n",
    "df2.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow'],\n",
    "                 marker = 'o',s=60,label='AFTER SCALING', ax = ax)\n",
    "plt.axhline(0, color='red',alpha=0.2)\n",
    "plt.axvline(0, color='red',alpha=0.2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
